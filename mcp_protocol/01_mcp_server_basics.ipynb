{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Context Protocol (MCP): Server Integration Fundamentals\n",
                "\n",
                "This notebook introduces **MCP (Model Context Protocol)**, Anthropic's open standard for connecting AI applications to external tools and data sources. MCP provides:\n",
                "1. **Standardized tool discovery**: Servers expose capabilities via a uniform interface\n",
                "2. **Language-agnostic integration**: Python and JavaScript servers work seamlessly\n",
                "3. **Ecosystem compatibility**: Growing marketplace of pre-built MCP servers\n",
                "\n",
                "**Key Pattern:** MCP separates tool implementation (servers) from agent logic (clients), enabling plug-and-play tool integration."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import dependencies\n",
                "from dotenv import load_dotenv\n",
                "from agents import Agent, Runner, trace\n",
                "from agents.mcp import MCPServerStdio\n",
                "import os\n",
                "\n",
                "load_dotenv(override=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 1: Connect to MCP Fetch Server (Python)\n",
                "\n",
                "The `mcp-server-fetch` provides web scraping capabilities."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize MCP Server\n",
                "fetch_params = {\"command\": \"uvx\", \"args\": [\"mcp-server-fetch\"]}\n",
                "\n",
                "async with MCPServerStdio(params=fetch_params, client_session_timeout_seconds=60) as server:\n",
                "    fetch_tools = await server.list_tools()\n",
                "\n",
                "fetch_tools"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2: Connect to MCP Playwright Server (JavaScript/Node.js)\n",
                "\n",
                "Browser automation via Playwright MCP server."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Playwright MCP Server\n",
                "playwright_params = {\"command\": \"npx\", \"args\": [\"@playwright/mcp@latest\"]}\n",
                "\n",
                "async with MCPServerStdio(params=playwright_params, client_session_timeout_seconds=60) as server:\n",
                "    playwright_tools = await server.list_tools()\n",
                "\n",
                "playwright_tools"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 3: Connect to Filesystem MCP Server"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filesystem MCP Server (Sandboxed)\n",
                "sandbox_path = os.path.abspath(os.path.join(os.getcwd(), \"sandbox\"))\n",
                "files_params = {\n",
                "    \"command\": \"npx\", \n",
                "    \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", sandbox_path]\n",
                "}\n",
                "\n",
                "async with MCPServerStdio(params=files_params, client_session_timeout_seconds=60) as server:\n",
                "    file_tools = await server.list_tools()\n",
                "\n",
                "file_tools"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 4: Build Agent with Multiple MCP Servers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Agent with Browser + File System Tools\n",
                "instructions = \"\"\"You browse the internet to accomplish tasks.\n",
                "You are highly capable at navigating websites independently, handling cookies, \n",
                "and finding content. If one site isn't helpful, try another. Be persistent.\"\"\"\n",
                "\n",
                "async with MCPServerStdio(params=files_params, client_session_timeout_seconds=60) as mcp_server_files:\n",
                "    async with MCPServerStdio(params=playwright_params, client_session_timeout_seconds=60) as mcp_server_browser:\n",
                "        agent = Agent(\n",
                "            name=\"web_researcher\", \n",
                "            instructions=instructions, \n",
                "            model=\"gpt-4o-mini\",\n",
                "            mcp_servers=[mcp_server_files, mcp_server_browser]\n",
                "        )\n",
                "        \n",
                "        with trace(\"research_task\"):\n",
                "            result = await Runner.run(\n",
                "                agent, \n",
                "                \"Find a great recipe for Banoffee Pie, then save it to banoffee.md\"\n",
                "            )\n",
                "            print(result.final_output)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## MCP Ecosystem Resources\n",
                "\n",
                "**MCP Marketplaces:**\n",
                "- [mcp.so](https://mcp.so)\n",
                "- [Glama AI MCP](https://glama.ai/mcp)\n",
                "- [Smithery](https://smithery.ai/)\n",
                "- [HuggingFace Top 11 MCP Libraries](https://huggingface.co/blog/LLMhacker/top-11-essential-mcp-libraries)\n",
                "- [HuggingFace MCP Community Article](https://huggingface.co/blog/Kseniase/mcp)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}