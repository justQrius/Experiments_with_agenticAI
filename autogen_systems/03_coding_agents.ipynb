{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AutoGen Core: Runtime Architecture & Agent Communication\n",
                "\n",
                "This notebook introduces **AutoGen Core**, a low-level framework for building distributed agent systems. Unlike AutoGen AgentChat (which provides pre-built agent abstractions), AutoGen Core offers fine-grained control over:\n",
                "1. **Message routing**: Custom message types and handlers\n",
                "2. **Runtime management**: Standalone vs. distributed execution\n",
                "3. **Agent lifecycle**: Registration, initialization, and shutdown\n",
                "\n",
                "**Key Pattern:** AutoGen Core decouples agent logic from message deliveryâ€”agents define behavior, the runtime handles communication."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import dependencies\n",
                "from dataclasses import dataclass\n",
                "from autogen_core import AgentId, MessageContext, RoutedAgent, message_handler\n",
                "from autogen_core import SingleThreadedAgentRuntime\n",
                "from autogen_agentchat.agents import AssistantAgent\n",
                "from autogen_agentchat.messages import TextMessage\n",
                "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
                "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv(override=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 1: Define Custom Message Type"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Custom Message Schema\n",
                "@dataclass\n",
                "class Message:\n",
                "    content: str"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2: Define Routed Agent\n",
                "\n",
                "**Agent ID Components:**\n",
                "- `agent.id.type`: Agent category (e.g., \"SimpleAgent\")\n",
                "- `agent.id.key`: Unique instance identifier (e.g., \"default\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple Agent Implementation\n",
                "class SimpleAgent(RoutedAgent):\n",
                "    def __init__(self) -> None:\n",
                "        super().__init__(\"SimpleAgent\")\n",
                "\n",
                "    @message_handler\n",
                "    async def on_my_message(self, message: Message, ctx: MessageContext) -> Message:\n",
                "        return Message(content=f\"{self.id.type}-{self.id.key}: I disagree with '{message.content}'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 3: Initialize Runtime & Register Agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create Runtime\n",
                "runtime = SingleThreadedAgentRuntime()\n",
                "await SimpleAgent.register(runtime, \"simple_agent\", lambda: SimpleAgent())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start Runtime & Send Message\n",
                "runtime.start()\n",
                "\n",
                "agent_id = AgentId(\"simple_agent\", \"default\")\n",
                "response = await runtime.send_message(Message(\"Well hi there!\"), agent_id)\n",
                "print(f\">>> {response.content}\")\n",
                "\n",
                "# Cleanup\n",
                "await runtime.stop()\n",
                "await runtime.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 4: Integrate AutoGen AgentChat Agents"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Wrapper for AgentChat Assistant\n",
                "class LLMAgent(RoutedAgent):\n",
                "    def __init__(self) -> None:\n",
                "        super().__init__(\"LLMAgent\")\n",
                "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
                "        self._delegate = AssistantAgent(\"LLMAgent\", model_client=model_client)\n",
                "\n",
                "    @message_handler\n",
                "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
                "        print(f\"{self.id.type} received: {message.content}\")\n",
                "        text_message = TextMessage(content=message.content, source=\"user\")\n",
                "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
                "        reply = response.chat_message.content\n",
                "        print(f\"{self.id.type} responded: {reply}\")\n",
                "        return Message(content=reply)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Register Multiple Agents\n",
                "runtime = SingleThreadedAgentRuntime()\n",
                "await SimpleAgent.register(runtime, \"simple_agent\", lambda: SimpleAgent())\n",
                "await LLMAgent.register(runtime, \"LLMAgent\", lambda: LLMAgent())\n",
                "\n",
                "runtime.start()\n",
                "\n",
                "# Multi-Agent Conversation\n",
                "response = await runtime.send_message(Message(\"Hi there!\"), AgentId(\"LLMAgent\", \"default\"))\n",
                "print(f\">>> {response.content}\")\n",
                "\n",
                "response = await runtime.send_message(Message(response.content), AgentId(\"simple_agent\", \"default\"))\n",
                "print(f\">>> {response.content}\")\n",
                "\n",
                "response = await runtime.send_message(Message(response.content), AgentId(\"LLMAgent\", \"default\"))\n",
                "print(f\">>> {response.content}\")\n",
                "\n",
                "await runtime.stop()\n",
                "await runtime.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 5: Multi-Agent Game (Rock, Paper, Scissors)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Player Agents (OpenAI vs. Ollama)\n",
                "class Player1Agent(RoutedAgent):\n",
                "    def __init__(self, name: str) -> None:\n",
                "        super().__init__(name)\n",
                "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=1.0)\n",
                "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
                "\n",
                "    @message_handler\n",
                "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
                "        text_message = TextMessage(content=message.content, source=\"user\")\n",
                "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
                "        return Message(content=response.chat_message.content)\n",
                "\n",
                "class Player2Agent(RoutedAgent):\n",
                "    def __init__(self, name: str) -> None:\n",
                "        super().__init__(name)\n",
                "        model_client = OllamaChatCompletionClient(model=\"llama3.2\", temperature=1.0)\n",
                "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
                "\n",
                "    @message_handler\n",
                "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
                "        text_message = TextMessage(content=message.content, source=\"user\")\n",
                "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
                "        return Message(content=response.chat_message.content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Game Orchestrator Agent\n",
                "JUDGE = \"You are judging rock, paper, scissors. The players chose:\\n\"\n",
                "\n",
                "class RockPaperScissorsAgent(RoutedAgent):\n",
                "    def __init__(self, name: str) -> None:\n",
                "        super().__init__(name)\n",
                "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=1.0)\n",
                "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
                "\n",
                "    @message_handler\n",
                "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
                "        instruction = \"Play rock, paper, scissors. Respond with only one word: rock, paper, or scissors.\"\n",
                "        msg = Message(content=instruction)\n",
                "        \n",
                "        # Send to both players\n",
                "        response1 = await self.send_message(msg, AgentId(\"player1\", \"default\"))\n",
                "        response2 = await self.send_message(msg, AgentId(\"player2\", \"default\"))\n",
                "        \n",
                "        # Judge winner\n",
                "        result = f\"Player 1: {response1.content}\\nPlayer 2: {response2.content}\\n\"\n",
                "        judgement = f\"{JUDGE}{result}Who wins?\"\n",
                "        text_msg = TextMessage(content=judgement, source=\"user\")\n",
                "        response = await self._delegate.on_messages([text_msg], ctx.cancellation_token)\n",
                "        return Message(content=result + response.chat_message.content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Register & Execute Game\n",
                "runtime = SingleThreadedAgentRuntime()\n",
                "await Player1Agent.register(runtime, \"player1\", lambda: Player1Agent(\"player1\"))\n",
                "await Player2Agent.register(runtime, \"player2\", lambda: Player2Agent(\"player2\"))\n",
                "await RockPaperScissorsAgent.register(runtime, \"rock_paper_scissors\", lambda: RockPaperScissorsAgent(\"rock_paper_scissors\"))\n",
                "\n",
                "runtime.start()\n",
                "\n",
                "# Play Game\n",
                "agent_id = AgentId(\"rock_paper_scissors\", \"default\")\n",
                "message = Message(content=\"go\")\n",
                "response = await runtime.send_message(message, agent_id)\n",
                "print(response.content)\n",
                "\n",
                "await runtime.stop()\n",
                "await runtime.close()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}