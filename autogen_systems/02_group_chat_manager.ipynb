{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AutoGen Advanced Patterns: Multi-Modal, Teams, and MCP Integration\n",
                "\n",
                "This notebook explores advanced AutoGen capabilities:\n",
                "1. **Multi-modal conversations**: Processing images alongside text\n",
                "2. **Structured outputs**: Type-safe responses using Pydantic schemas\n",
                "3. **LangChain tool integration**: Leveraging LangChain's rich ecosystem\n",
                "4. **Team collaboration**: Multi-agent workflows with round-robin coordination\n",
                "5. **MCP (Model Context Protocol)**: Anthropic's standard for tool integration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import dependencies\n",
                "from io import BytesIO\n",
                "import requests\n",
                "from autogen_agentchat.messages import TextMessage, MultiModalMessage\n",
                "from autogen_core import Image as AGImage\n",
                "from PIL import Image\n",
                "from dotenv import load_dotenv\n",
                "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
                "from autogen_agentchat.agents import AssistantAgent\n",
                "from autogen_core import CancellationToken\n",
                "from IPython.display import display, Markdown\n",
                "from pydantic import BaseModel, Field\n",
                "from typing import Literal\n",
                "import textwrap\n",
                "\n",
                "load_dotenv(override=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 1: Multi-Modal Image Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Image from URL\n",
                "url = \"https://edwarddonner.com/wp-content/uploads/2024/10/from-software-engineer-to-AI-DS.jpeg\"\n",
                "pil_image = Image.open(BytesIO(requests.get(url).content))\n",
                "img = AGImage(pil_image)\n",
                "img"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create Multi-Modal Message\n",
                "multi_modal_message = MultiModalMessage(\n",
                "    content=[\"Describe the content of this image in detail\", img], \n",
                "    source=\"User\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vision-Enabled Agent\n",
                "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
                "\n",
                "describer = AssistantAgent(\n",
                "    name=\"image_analyst\",\n",
                "    model_client=model_client,\n",
                "    system_message=\"You are skilled at analyzing images and providing detailed descriptions.\",\n",
                ")\n",
                "\n",
                "response = await describer.on_messages([multi_modal_message], cancellation_token=CancellationToken())\n",
                "display(Markdown(response.chat_message.content))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2: Structured Outputs with Pydantic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define Output Schema\n",
                "class ImageDescription(BaseModel):\n",
                "    scene: str = Field(description=\"Brief description of the overall scene\")\n",
                "    message: str = Field(description=\"The point the image is trying to convey\")\n",
                "    style: str = Field(description=\"The artistic style of the image\")\n",
                "    orientation: Literal[\"portrait\", \"landscape\", \"square\"] = Field(description=\"Image orientation\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Agent with Structured Output\n",
                "describer = AssistantAgent(\n",
                "    name=\"structured_analyst\",\n",
                "    model_client=model_client,\n",
                "    system_message=\"Analyze images and provide structured descriptions.\",\n",
                "    output_content_type=ImageDescription,\n",
                ")\n",
                "\n",
                "response = await describer.on_messages([multi_modal_message], cancellation_token=CancellationToken())\n",
                "reply = response.chat_message.content\n",
                "\n",
                "# Display Structured Output\n",
                "print(f\"Scene: {reply.scene}\\n\")\n",
                "print(f\"Message: {reply.message}\\n\")\n",
                "print(f\"Style: {reply.style}\\n\")\n",
                "print(f\"Orientation: {reply.orientation}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 3: LangChain Tool Integration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import LangChain Tools\n",
                "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
                "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
                "from langchain_community.agent_toolkits import FileManagementToolkit\n",
                "from langchain.agents import Tool\n",
                "\n",
                "# Wrap LangChain Tools\n",
                "serper = GoogleSerperAPIWrapper()\n",
                "langchain_serper = Tool(\n",
                "    name=\"internet_search\", \n",
                "    func=serper.run, \n",
                "    description=\"Search the internet\"\n",
                ")\n",
                "autogen_serper = LangChainToolAdapter(langchain_serper)\n",
                "\n",
                "# File Management Tools\n",
                "autogen_tools = [autogen_serper]\n",
                "langchain_file_tools = FileManagementToolkit(root_dir=\"sandbox\").get_tools()\n",
                "for tool in langchain_file_tools:\n",
                "    autogen_tools.append(LangChainToolAdapter(tool))\n",
                "\n",
                "# Display Available Tools\n",
                "for tool in autogen_tools:\n",
                "    print(f\"{tool.name}: {tool.description}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Task: Flight Search with File Writing\n",
                "prompt = \"\"\"Find a one-way non-stop flight from JFK to LHR in June 2025.\n",
                "Search online for deals, write them to flights.md, then select the best option.\"\"\"\n",
                "\n",
                "agent = AssistantAgent(\n",
                "    name=\"flight_researcher\", \n",
                "    model_client=model_client, \n",
                "    tools=autogen_tools, \n",
                "    reflect_on_tool_use=True\n",
                ")\n",
                "\n",
                "message = TextMessage(content=prompt, source=\"user\")\n",
                "result = await agent.on_messages([message], cancellation_token=CancellationToken())\n",
                "\n",
                "# Show Internal Workflow\n",
                "for msg in result.inner_messages:\n",
                "    print(f\"[Tool Call] {msg.content}\")\n",
                "\n",
                "display(Markdown(result.chat_message.content))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 4: Multi-Agent Team Collaboration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Team Setup\n",
                "from autogen_agentchat.agents import AssistantAgent\n",
                "from autogen_agentchat.conditions import TextMentionTermination\n",
                "from autogen_agentchat.teams import RoundRobinGroupChat\n",
                "\n",
                "# Define Team Members\n",
                "primary_agent = AssistantAgent(\n",
                "    \"researcher\",\n",
                "    model_client=model_client,\n",
                "    tools=[autogen_serper],\n",
                "    system_message=\"Research flight deals and incorporate feedback.\",\n",
                ")\n",
                "\n",
                "evaluation_agent = AssistantAgent(\n",
                "    \"evaluator\",\n",
                "    model_client=model_client,\n",
                "    system_message=\"Provide constructive feedback. Respond with 'APPROVE' when satisfied.\",\n",
                ")\n",
                "\n",
                "# Termination Condition\n",
                "text_termination = TextMentionTermination(\"APPROVE\")\n",
                "\n",
                "# Create Team\n",
                "team = RoundRobinGroupChat(\n",
                "    [primary_agent, evaluation_agent], \n",
                "    termination_condition=text_termination, \n",
                "    max_turns=20\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Execute Team Workflow\n",
                "prompt = \"Find a one-way non-stop flight from JFK to LHR in June 2025.\"\n",
                "result = await team.run(task=prompt)\n",
                "\n",
                "# Display Conversation\n",
                "for message in result.messages:\n",
                "    print(f\"{message.source}:\\n{message.content}\\n\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 5: MCP (Model Context Protocol) Integration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# MCP Server Tools\n",
                "from autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools\n",
                "\n",
                "# Configure MCP Fetch Server\n",
                "fetch_mcp_server = StdioServerParams(\n",
                "    command=\"uvx\", \n",
                "    args=[\"mcp-server-fetch\"], \n",
                "    read_timeout_seconds=30\n",
                ")\n",
                "fetcher = await mcp_server_tools(fetch_mcp_server)\n",
                "\n",
                "# Agent with MCP Tools\n",
                "agent = AssistantAgent(\n",
                "    name=\"web_fetcher\", \n",
                "    model_client=model_client, \n",
                "    tools=fetcher, \n",
                "    reflect_on_tool_use=True\n",
                ")\n",
                "\n",
                "# Execute Web Scraping Task\n",
                "result = await agent.run(task=\"Review edwarddonner.com and summarize what you learn. Reply in Markdown.\")\n",
                "display(Markdown(result.messages[-1].content))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}