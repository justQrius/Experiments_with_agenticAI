{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multi-Agent Collaboration: Worker-Evaluator Pattern\n",
                "\n",
                "This notebook implements a sophisticated two-agent system:\n",
                "1. **Worker Agent**: Executes tasks using browser automation tools\n",
                "2. **Evaluator Agent**: Validates output against success criteria, providing feedback loops\n",
                "\n",
                "**Pattern:** This \"worker + evaluator\" architecture ensures quality control through iterative refinementâ€”the evaluator can reject unsatisfactory work and request revisions until success criteria are met.\n",
                "\n",
                "**Use Cases:**\n",
                "- Content generation with quality gates\n",
                "- Autonomous task execution with validation\n",
                "- Self-healing workflows"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import dependencies\n",
                "from typing import Annotated, TypedDict, List, Dict, Any, Optional\n",
                "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_community.agent_toolkits import PlayWrightBrowserToolkit\n",
                "from langchain_community.tools.playwright.utils import create_async_playwright_browser\n",
                "from langgraph.graph import StateGraph, START, END\n",
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "from langgraph.prebuilt import ToolNode\n",
                "from langgraph.graph.message import add_messages\n",
                "from pydantic import BaseModel, Field\n",
                "from IPython.display import Image, display\n",
                "import gradio as gr\n",
                "import uuid\n",
                "import nest_asyncio\n",
                "from dotenv import load_dotenv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Environment\n",
                "load_dotenv(override=True)\n",
                "nest_asyncio.apply()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Define State & Output Schemas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluator Structured Output\n",
                "class EvaluatorOutput(BaseModel):\n",
                "    feedback: str = Field(description=\"Feedback on the worker's response\")\n",
                "    success_criteria_met: bool = Field(description=\"Whether success criteria have been met\")\n",
                "    user_input_needed: bool = Field(description=\"True if more user input is required\")\n",
                "\n",
                "# State Schema\n",
                "class State(TypedDict):\n",
                "    messages: Annotated[List[Any], add_messages]\n",
                "    success_criteria: str\n",
                "    feedback_on_work: Optional[str]\n",
                "    success_criteria_met: bool\n",
                "    user_input_needed: bool"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configure Tools & LLMs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Playwright Browser Tools\n",
                "async_browser = create_async_playwright_browser(headless=False)\n",
                "toolkit = PlayWrightBrowserToolkit.from_browser(async_browser=async_browser)\n",
                "tools = toolkit.get_tools()\n",
                "\n",
                "# LLM Clients\n",
                "worker_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
                "worker_llm_with_tools = worker_llm.bind_tools(tools)\n",
                "\n",
                "evaluator_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
                "evaluator_llm_with_output = evaluator_llm.with_structured_output(EvaluatorOutput)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Define Agent Nodes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Worker Agent Node\n",
                "def worker(state: State) -> Dict[str, Any]:\n",
                "    \"\"\"Executes the task with tools, incorporating evaluator feedback if rejected previously.\"\"\"\n",
                "    system_message = f\"\"\"You are a helpful assistant with browser automation tools.\n",
                "Work until you complete the task, have a question for the user, or the success criteria is met.\n",
                "\n",
                "Success Criteria:\n",
                "{state['success_criteria']}\n",
                "\n",
                "If you have a question, clearly state it. Example: \"Question: Do you want a summary or detailed answer?\"\n",
                "If finished, provide the final answer without asking a question.\n",
                "\"\"\"\n",
                "    \n",
                "    # Incorporate rejection feedback if present\n",
                "    if state.get(\"feedback_on_work\"):\n",
                "        system_message += f\"\\n\\nPrevious Rejection Feedback:\\n{state['feedback_on_work']}\\nPlease revise accordingly.\"\n",
                "    \n",
                "    # Update or add system message\n",
                "    messages = state[\"messages\"].copy()\n",
                "    found_system = any(isinstance(m, SystemMessage) for m in messages)\n",
                "    if found_system:\n",
                "        for msg in messages:\n",
                "            if isinstance(msg, SystemMessage):\n",
                "                msg.content = system_message\n",
                "    else:\n",
                "        messages = [SystemMessage(content=system_message)] + messages\n",
                "    \n",
                "    response = worker_llm_with_tools.invoke(messages)\n",
                "    return {\"messages\": [response]}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluator Agent Node\n",
                "def evaluator(state: State) -> State:\n",
                "    \"\"\"Evaluates worker output against success criteria.\"\"\"\n",
                "    last_response = state[\"messages\"][-1].content\n",
                "\n",
                "    system_message = \"\"\"You evaluate whether an assistant's response meets success criteria. \n",
                "Provide feedback and determine if: (1) criteria met, (2) user input needed.\"\"\"\n",
                "\n",
                "    conversation = format_conversation(state['messages'])\n",
                "    user_message = f\"\"\"Conversation:\n",
                "{conversation}\n",
                "\n",
                "Success Criteria:\n",
                "{state['success_criteria']}\n",
                "\n",
                "Assistant's Final Response:\n",
                "{last_response}\n",
                "\n",
                "Provide feedback and decision.\n",
                "\"\"\"\n",
                "\n",
                "    evaluator_messages = [SystemMessage(content=system_message), HumanMessage(content=user_message)]\n",
                "    eval_result = evaluator_llm_with_output.invoke(evaluator_messages)\n",
                "\n",
                "    return {\n",
                "        \"messages\": [{\"role\": \"assistant\", \"content\": f\"Evaluator: {eval_result.feedback}\"}],\n",
                "        \"feedback_on_work\": eval_result.feedback,\n",
                "        \"success_criteria_met\": eval_result.success_criteria_met,\n",
                "        \"user_input_needed\": eval_result.user_input_needed\n",
                "    }\n",
                "\n",
                "def format_conversation(messages: List[Any]) -> str:\n",
                "    \"\"\"Formats message history for evaluator.\"\"\"\n",
                "    conversation = \"Conversation History:\\n\"\n",
                "    for message in messages:\n",
                "        if isinstance(message, HumanMessage):\n",
                "            conversation += f\"User: {message.content}\\n\"\n",
                "        elif isinstance(message, AIMessage):\n",
                "            text = message.content or \"[Tool Execution]\"\n",
                "            conversation += f\"Assistant: {text}\\n\"\n",
                "    return conversation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Define Routing Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Route from Worker\n",
                "def worker_router(state: State) -> str:\n",
                "    last_message = state[\"messages\"][-1]\n",
                "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
                "        return \"tools\"\n",
                "    else:\n",
                "        return \"evaluator\"\n",
                "\n",
                "# Route from Evaluator\n",
                "def route_based_on_evaluation(state: State) -> str:\n",
                "    if state[\"success_criteria_met\"] or state[\"user_input_needed\"]:\n",
                "        return \"END\"\n",
                "    else:\n",
                "        return \"worker\"  # Retry loop"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Build & Compile Graph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build Graph\n",
                "graph_builder = StateGraph(State)\n",
                "\n",
                "# Add Nodes\n",
                "graph_builder.add_node(\"worker\", worker)\n",
                "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
                "graph_builder.add_node(\"evaluator\", evaluator)\n",
                "\n",
                "# Add Edges\n",
                "graph_builder.add_conditional_edges(\"worker\", worker_router, {\"tools\": \"tools\", \"evaluator\": \"evaluator\"})\n",
                "graph_builder.add_edge(\"tools\", \"worker\")\n",
                "graph_builder.add_conditional_edges(\"evaluator\", route_based_on_evaluation, {\"worker\": \"worker\", \"END\": END})\n",
                "graph_builder.add_edge(START, \"worker\")\n",
                "\n",
                "# Compile\n",
                "memory = MemorySaver()\n",
                "graph = graph_builder.compile(checkpointer=memory)\n",
                "display(Image(graph.get_graph().draw_mermaid_png()))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Launch Interactive UI"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Workflow Execution\n",
                "def make_thread_id() -> str:\n",
                "    return str(uuid.uuid4())\n",
                "\n",
                "async def process_message(message, success_criteria, history, thread):\n",
                "    config = {\"configurable\": {\"thread_id\": thread}}\n",
                "    state = {\n",
                "        \"messages\": message,\n",
                "        \"success_criteria\": success_criteria,\n",
                "        \"feedback_on_work\": None,\n",
                "        \"success_criteria_met\": False,\n",
                "        \"user_input_needed\": False\n",
                "    }\n",
                "    result = await graph.ainvoke(state, config=config)\n",
                "    \n",
                "    user_msg = {\"role\": \"user\", \"content\": message}\n",
                "    reply = {\"role\": \"assistant\", \"content\": result[\"messages\"][-2].content}\n",
                "    feedback = {\"role\": \"assistant\", \"content\": result[\"messages\"][-1].content}\n",
                "    return history + [user_msg, reply, feedback]\n",
                "\n",
                "async def reset():\n",
                "    return \"\", \"\", None, make_thread_id()\n",
                "\n",
                "# Gradio Interface\n",
                "with gr.Blocks(theme=gr.themes.Default(primary_hue=\"emerald\")) as demo:\n",
                "    gr.Markdown(\"## Sidekick: Autonomous Co-Worker\")\n",
                "    thread = gr.State(make_thread_id())\n",
                "    \n",
                "    chatbot = gr.Chatbot(label=\"Sidekick\", height=300, type=\"messages\")\n",
                "    message = gr.Textbox(placeholder=\"Your request\")\n",
                "    success_criteria = gr.Textbox(placeholder=\"Success criteria\")\n",
                "    \n",
                "    with gr.Row():\n",
                "        reset_button = gr.Button(\"Reset\", variant=\"stop\")\n",
                "        go_button = gr.Button(\"Go!\", variant=\"primary\")\n",
                "    \n",
                "    go_button.click(process_message, [message, success_criteria, chatbot, thread], [chatbot])\n",
                "    reset_button.click(reset, [], [message, success_criteria, chatbot, thread])\n",
                "\n",
                "demo.launch()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}