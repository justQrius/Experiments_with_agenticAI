{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LangGraph: Tool Integration & Persistent Memory\n",
                "\n",
                "This notebook demonstrates advanced LangGraph patterns:\n",
                "1. **Tool Binding**: Connecting external tools (web search, notifications) to LangGraph agents\n",
                "2. **Cyclic Graphs**: Implementing feedback loops where agents can call tools and re-process results\n",
                "3. **Checkpointing**: Persisting conversation state across invocations using `MemorySaver` and `SqliteSaver`\n",
                "\n",
                "**Key Concept:** LangGraph's \"super-step\" architecture requires explicit checkpointing to maintain state between invocations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import dependencies\n",
                "from typing import Annotated\n",
                "from langgraph.graph import StateGraph, START\n",
                "from langgraph.graph.message import add_messages\n",
                "from dotenv import load_dotenv\n",
                "from IPython.display import Image, display\n",
                "import gradio as gr\n",
                "from langgraph.prebuilt import ToolNode, tools_condition\n",
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "from langgraph.checkpoint.sqlite import SqliteSaver\n",
                "import requests\n",
                "import os\n",
                "import sqlite3\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain.agents import Tool\n",
                "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
                "from typing import TypedDict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Environment\n",
                "load_dotenv(override=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 1: Define Tools\n",
                "\n",
                "Using LangChain's `Tool` wrapper to create agent-compatible functions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Web Search Tool (via Serper API)\n",
                "serper = GoogleSerperAPIWrapper()\n",
                "tool_search = Tool(\n",
                "    name=\"search\",\n",
                "    func=serper.run,\n",
                "    description=\"Search the web for current information\"\n",
                ")\n",
                "\n",
                "# Test\n",
                "tool_search.invoke(\"What is the capital of France?\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Push Notification Tool\n",
                "def push(text: str):\n",
                "    \"\"\"Send push notification via Pushover\"\"\"\n",
                "    token = os.getenv(\"PUSHOVER_TOKEN\")\n",
                "    user = os.getenv(\"PUSHOVER_USER\")\n",
                "    if token and user:\n",
                "        requests.post(\"https://api.pushover.net/1/messages.json\", \n",
                "                      data={\"token\": token, \"user\": user, \"message\": text})\n",
                "\n",
                "tool_push = Tool(\n",
                "    name=\"send_push_notification\",\n",
                "    func=push,\n",
                "    description=\"Send a push notification to the user\"\n",
                ")\n",
                "\n",
                "tools = [tool_search, tool_push]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2: Build Cyclic Graph with Tools"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define State\n",
                "class State(TypedDict):\n",
                "    messages: Annotated[list, add_messages]\n",
                "\n",
                "# Initialize Graph\n",
                "graph_builder = StateGraph(State)\n",
                "\n",
                "# LLM with Tool Bindings\n",
                "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
                "llm_with_tools = llm.bind_tools(tools)\n",
                "\n",
                "# Chatbot Node\n",
                "def chatbot(state: State):\n",
                "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
                "\n",
                "# Add Nodes\n",
                "graph_builder.add_node(\"chatbot\", chatbot)\n",
                "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
                "\n",
                "# Add Edges (Cyclic: chatbot â†” tools)\n",
                "graph_builder.add_conditional_edges(\"chatbot\", tools_condition, \"tools\")\n",
                "graph_builder.add_edge(\"tools\", \"chatbot\")  # Return to chatbot after tool execution\n",
                "graph_builder.add_edge(START, \"chatbot\")\n",
                "\n",
                "# Compile (No Memory Yet)\n",
                "graph = graph_builder.compile()\n",
                "display(Image(graph.get_graph().draw_mermaid_png()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test Execution (Stateless)\n",
                "def chat(user_input: str, history):\n",
                "    result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]})\n",
                "    return result[\"messages\"][-1].content\n",
                "\n",
                "gr.ChatInterface(chat, type=\"messages\").launch()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 3: Add Memory (In-Memory Checkpointing)\n",
                "\n",
                "**Why Checkpointing?** LangGraph's state is scoped to a single invocation (\"super-step\"). To maintain context across multiple user interactions, we need persistence."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configure Memory\n",
                "memory = MemorySaver()\n",
                "\n",
                "# Rebuild Graph with Checkpointing\n",
                "graph_builder = StateGraph(State)\n",
                "graph_builder.add_node(\"chatbot\", chatbot)\n",
                "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
                "graph_builder.add_conditional_edges(\"chatbot\", tools_condition, \"tools\")\n",
                "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
                "graph_builder.add_edge(START, \"chatbot\")\n",
                "\n",
                "graph = graph_builder.compile(checkpointer=memory)\n",
                "display(Image(graph.get_graph().draw_mermaid_png()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Execute with Memory (Thread-based Persistence)\n",
                "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
                "\n",
                "def chat(user_input: str, history):\n",
                "    result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config=config)\n",
                "    return result[\"messages\"][-1].content\n",
                "\n",
                "gr.ChatInterface(chat, type=\"messages\").launch()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inspect State\n",
                "graph.get_state(config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View State History (Time-travel Debugging)\n",
                "list(graph.get_state_history(config))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 4: Persistent Memory (SQLite Checkpointing)\n",
                "\n",
                "Upgrading to database-backed persistence for production resilience."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configure SQLite Checkpointer\n",
                "db_path = \"memory.db\"\n",
                "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
                "sql_memory = SqliteSaver(conn)\n",
                "\n",
                "# Rebuild Graph with SQL Persistence\n",
                "graph_builder = StateGraph(State)\n",
                "graph_builder.add_node(\"chatbot\", chatbot)\n",
                "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
                "graph_builder.add_conditional_edges(\"chatbot\", tools_condition, \"tools\")\n",
                "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
                "graph_builder.add_edge(START, \"chatbot\")\n",
                "\n",
                "graph = graph_builder.compile(checkpointer=sql_memory)\n",
                "display(Image(graph.get_graph().draw_mermaid_png()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Execute with Persistent Memory\n",
                "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
                "\n",
                "def chat(user_input: str, history):\n",
                "    result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config=config)\n",
                "    return result[\"messages\"][-1].content\n",
                "\n",
                "gr.ChatInterface(chat, type=\"messages\").launch()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}